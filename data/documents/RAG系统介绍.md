# RAG 系统介绍

## 什么是 RAG？

RAG（Retrieval-Augmented Generation，检索增强生成）是一种将信息检索与文本生成相结合的技术。它通过先从知识库中检索相关文档，然后基于检索到的内容生成回答。

## RAG 的优势

### 1. 减少幻觉

传统的大语言模型（LLM）可能会生成看似合理但不准确的信息，这被称为"幻觉"。RAG 通过提供真实的上下文来约束模型生成。

### 2. 知识更新

LLM 的知识截止于训练数据的时间点。RAG 允许动态更新知识库，无需重新训练模型。

### 3. 来源可追溯

RAG 可以提供回答的来源，增加可信度和可验证性。

### 4. 降低成本

相比于微调大模型，RAG 只需要维护向量数据库，成本更低。

## RAG 工作流程

1. **文档处理**：将文档切分成小块
2. **向量化**：使用嵌入模型将文本转换为向量
3. **存储**：将向量存入向量数据库
4. **检索**：根据查询找到最相关的文档块
5. **生成**：将检索结果作为上下文，让 LLM 生成回答

## 向量数据库

向量数据库专门用于存储和检索高维向量。常见选择：

- ChromaDB（本地、轻量）
- Pinecone（云托管）
- Weaviate（开源）
- Milvus（高性能）
- FAISS（Facebook 开源）

## 嵌入模型

嵌入模型将文本转换为固定维度的向量表示。常用模型：

- OpenAI text-embedding-3-small
- Google embedding-001
- sentence-transformers（开源）
- BGE（中文优化）

## 最佳实践

### 文档切分

- 块大小：500-1000 字符
- 重叠：块之间有 100-200 字符重叠
- 保持语义完整性

### 检索优化

- 混合检索：结合关键词和向量检索
- 重排序：对初始结果进行精排
- 查询扩展：增强原始查询

### 提示工程

- 明确指示模型只使用提供的上下文
- 要求引用来源
- 处理没有相关信息的情况

## 应用场景

- 企业知识库问答
- 客服智能助手
- 文档分析
- 代码助手
- 医疗问诊辅助
